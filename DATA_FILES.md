# Data Files Management

## Overview

Due to GitHub's file size limitations, some large data files are excluded from this repository. This document explains which files are excluded, why, and how to obtain them.

## Excluded Files

### 1. `litigation-cases.json` (117MB)
- **Size**: 117MB
- **Reason**: Exceeds GitHub's 100MB hard limit for individual files
- **Content**: Complete dataset of 11,772 SEC litigation cases with metadata
- **Status**: Excluded from repository

### 2. `sec-cases.json` (46MB)
- **Size**: 46MB
- **Reason**: Exceeds GitHub's 50MB warning threshold
- **Content**: Filtered subset of cases with complaint PDFs (4,155 cases)
- **Status**: Excluded from repository

### 3. `cursor_sec_cases_data_structure_and_fea.md` (147MB)
- **Size**: 147MB
- **Reason**: Very large markdown documentation file
- **Content**: Documentation and data structure information
- **Status**: Excluded from repository

## GitHub File Size Limits

- **Hard Limit**: 100MB per file (files over this cannot be pushed)
- **Warning Threshold**: 50MB (files over this trigger warnings)
- **Recommendation**: Use Git LFS for files over 50MB, or exclude them

## Obtaining Data Files

### Option 1: Generate from SEC Sources

The data files can be regenerated by scraping SEC litigation releases:

```bash
# The dataset was originally created by scraping SEC.gov
# See src/preprocessing/ for data collection scripts
```

### Option 2: Request from Maintainers

For research or development purposes, you can:
- Open an issue requesting access to the data files
- Contact the maintainers for data file access
- Check if data files are available via alternative hosting (e.g., Zenodo, Google Drive)

### Option 3: Use API Server

The API server (`api_server.py`) provides programmatic access to all case data:

```bash
# Start the API server (requires litigation-cases.json locally)
python api_server.py

# Access data via API endpoints
curl http://localhost:5000/api/cases?page=1&per_page=100
```

## Local Development Setup

### For API Server

1. **Obtain `litigation-cases.json`** (117MB)
   - Place it in the repository root directory
   - The API server will automatically load it
   - File is already in `.gitignore` so it won't be committed

2. **Verify setup**:
   ```bash
   python api_server.py
   # Should see: "✓ Cases loaded successfully"
   ```

### For Evaluations

1. **Obtain `sec-cases.json`** (46MB) - Optional
   - Only needed if running dataset building scripts
   - Place in repository root
   - Already in `.gitignore`

2. **Processed data files** in `data/processed/`:
   - `evaluation_dataset.json` (2.2MB) - Included in repo
   - `combined_results.json` (12MB) - Included in repo
   - `evaluation_results_*.json` - Included in repo

## Alternative Storage Options

### Git LFS (Git Large File Storage)

If you need to version control large files:

```bash
# Install Git LFS
git lfs install

# Track large files
git lfs track "*.json"
git lfs track "litigation-cases.json"
git lfs track "sec-cases.json"

# Note: Git LFS requires a GitHub account with LFS bandwidth
```

### External Hosting

Consider hosting large data files on:
- **Zenodo** - Research data repository (free, DOI assignment)
- **Google Drive / Dropbox** - Share links in documentation
- **AWS S3 / Cloud Storage** - For programmatic access
- **Hugging Face Datasets** - For ML/AI datasets

## Included Data Files

The following data files **are included** in the repository:

- `data/processed/evaluation_dataset.json` (2.2MB) ✓
- `data/processed/combined_results.json` (12MB) ✓
- `data/processed/evaluation_results_openai.json` (2.4MB) ✓
- `data/processed/evaluation_results_anthropic.json` (1.9MB) ✓
- `data/processed/evaluation_results_google.json` (3.0MB) ✓
- `sample_reducto_export.json` (2.6KB) ✓

These files are under GitHub's limits and provide sufficient data for:
- Viewing evaluation results
- Running the website
- Understanding the data structure
- Testing the API (if you have the full dataset locally)

## Questions?

If you need access to the full dataset files:
1. Check if they're available via the API server
2. Open an issue requesting access
3. Contact the maintainers

For questions about data structure or usage, see:
- [README.md](README.md) - General documentation
- [API_README.md](API_README.md) - API documentation
- [CONTRIBUTING.md](CONTRIBUTING.md) - Development setup
